\section{总结与感想}

本次实验的基础部分，我们实现了一个有较高健壮性的算符优先分析表生成器，这个分析表不但能够分析正确的文法，对于错误的文法、不规范的文法和有二义性的文法也有对应的处理与错误提示。

本次实验的加分项中，我们使用TVM框架实现了对卷积计算的高性能优化，不论是小规模还是大规模的输入都能够得到较好的优化。

\begin{itemize}
    \item 对于知识点的准确掌握。课程和教程中的知识点都比较空泛，有一个较为抽象的理解，但是对于具体的操作，仍然要实践出真知。通过本次实验，我们对于算符优先文法和TVM的各种优化原语都有了较深刻的理解。
    \item 环境的配置。TVM框架仍然处于孵化阶段，版本之间的API差异比较大，而且版本之间对于LLVM的依赖不同，与其他成熟的框架相比，文档、示例、编译都比较欠缺，除了与GitHub同步的0.8.dev0版本，其他代码都无法正确变异。通过认真翻阅API文档，我们完成了环境配置，并在此基础上完成了实验。
    \item 团队的协作。因为本项目并非是能够拆分的传统项目，对于团队的协作提出了较大的挑战性。我们使用git进行版本的迭代和团队的协作，并通过GitLab提供的Worker功能进行持续集成，对程序的正确性进行实时判断，尤其是第二个项目，耗时较长，使用CI/CD和自动化测试后，程序的开发效率得到了很好的提升。
\end{itemize}

通过本次编译原理大作业的学习，我们对于算符优先文法、TVM框架，和深度学习中的矩阵计算优化手段都有了更好的理解。编译器以其牵一发而动全身的地位，算法的设计尤为重要。此次通过重温实现经典算法、探索深度学习编译器的优化前沿，对于我们普通程序的编写和优化也是大有裨益的。

编译原理的课时很短，因为课程进度的设计原因，在课堂教学中，对于编译器的近代进展只是蜻蜓点水。感谢蒋力老师与助教们的精心设计与辛勤付出，为我们提供了这样一个难得的机会。最后要感谢上海交通大学，为我们提供了这样一门精彩纷呈的课程。